{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be141a7a-4242-45bf-be71-b1a6e6067c83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13e6f109-5913-4060-9466-e3ae494b9803",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Generate the access token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61518baa-6b7f-4e07-a04c-dd95e27663c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "\n",
    "export CLIENT_ID=c29a0539-c265-4284-8298-20dd41ca124c\n",
    "export CLIENT_SECRET=\n",
    "\n",
    "  curl --request POST \\\n",
    "  --url \"https://accounts.cloud.databricks.com/oidc/accounts/b4b3a7b6-ad44-4f55-9f2b-5cc18881ee38/v1/token\" \\\n",
    "  --user \"$CLIENT_ID:$CLIENT_SECRET\" \\\n",
    "  --data 'grant_type=client_credentials&scope=all-apis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28646f8b-0a96-4117-aafb-62a24ad5d8fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Install all the Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8e91e9e-82ab-4742-b367-c2f5b80a1675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -qqq mlflow langgraph==0.3.4 databricks-langchain databricks-agents uv databricks-vectorsearch\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8e009cc-250a-4734-9979-815b894de0a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Configure the Langgraph agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9908071-33bc-4557-a758-61008ffa2728",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile agent.py\n",
    "import functools\n",
    "import os\n",
    "from typing import Any, Generator, Literal, Optional\n",
    "\n",
    "import mlflow\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    UCFunctionToolkit,\n",
    ")\n",
    "from databricks_langchain.genie import GenieAgent\n",
    "from databricks_langchain import DatabricksVectorSearch\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "from pydantic import BaseModel\n",
    "\n",
    "###################################################\n",
    "## Create a GenieAgent with access to a Genie Space\n",
    "###################################################\n",
    "\n",
    "# TODO add GENIE_SPACE_ID and a description for this space\n",
    "# You can find the ID in the URL of the genie room /genie/rooms/<GENIE_SPACE_ID>\n",
    "GENIE_SPACE_ID = \"01f0454b13a0192c9419325353b3aa99\"\n",
    "genie_agent_description = \"This agent can help find the right Medicare plan for a person based on a given set of filtered Medicare plans that are available in the state\"\n",
    "\n",
    "genie_agent = GenieAgent(\n",
    "    genie_space_id=GENIE_SPACE_ID,\n",
    "    genie_agent_name=\"Genie\",\n",
    "    description=genie_agent_description,\n",
    "    client=WorkspaceClient(\n",
    "        host=os.getenv(\"DB_MODEL_SERVING_HOST_URL\"),\n",
    "        token=os.getenv(\"DATABRICKS_GENIE_PAT\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "#######################################\n",
    "# Define enhanced Genie agent wrapper\n",
    "#######################################\n",
    "\n",
    "def enhanced_genie_agent(state):\n",
    "    \"\"\"Enhanced Genie agent that gets proper context about retrieved plans\"\"\"\n",
    "    \n",
    "    # Get the plan IDs from the state\n",
    "    contract_ids = state.get(\"contract_ids\", [])\n",
    "    \n",
    "    if not contract_ids:\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"I need specific Medicare contract IDs to provide detailed benefit information. Let me help you find some plans first.\",\n",
    "                    \"name\": \"Genie\",\n",
    "                }\n",
    "            ],\n",
    "            \"needs_user_input\": False\n",
    "        }\n",
    "    \n",
    "    # Create a focused query for Genie with specific contract IDs\n",
    "    genie_query = f\"\"\"\n",
    "    I need help comparing Medicare plans for someone.\n",
    "    \n",
    "    Please provide detailed benefit information and recommendations for these specific Medicare contract IDs:\n",
    "    \n",
    "    All contract_id (can also be called contract_number): {', '.join(contract_ids)}\n",
    "    \n",
    "    Focus on:\n",
    "    - Plan benefits and coverage details\n",
    "    - Costs (premiums, deductibles, copays)\n",
    "    - Prescription drug coverage if applicable\n",
    "    - Network coverage\n",
    "    - Which plan would be best suited for the person's stated needs\n",
    "\n",
    "    Use those tables:\n",
    "    - mapd_plan_directory (filter by contract_number)\n",
    "    - mpf_benefit_summary (filter by contract_id and contract_year:2025)\n",
    "    - pbp_plan_area (filter by contract_id)\n",
    "\n",
    "    Filter all those tables by state of NY and county is \"dutchess\" .\n",
    "\n",
    "    Do not ask a follow up question to the user.\n",
    "    \"\"\"\n",
    "\n",
    "    isolated_genie = GenieAgent(\n",
    "        genie_space_id=GENIE_SPACE_ID,\n",
    "        genie_agent_name=\"Genie\",\n",
    "        description=genie_agent_description,\n",
    "        client=WorkspaceClient(\n",
    "            host=os.getenv(\"DB_MODEL_SERVING_HOST_URL\"),\n",
    "            token=os.getenv(\"DATABRICKS_GENIE_PAT\"),\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    # Create a new state with just the focused query\n",
    "    genie_state = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": genie_query\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Call the Genie agent with the focused query\n",
    "        result = isolated_genie.invoke(genie_state)\n",
    "        \n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": result[\"messages\"][-1].content,\n",
    "                    \"name\": \"Genie\",\n",
    "                }\n",
    "            ],\n",
    "            \"needs_user_input\": False\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": f\"I encountered an issue getting detailed plan information: {str(e)}. Based on the retrieved plans, I can still help you with general guidance about your Medicare options.\",\n",
    "                    \"name\": \"Genie\",\n",
    "                }\n",
    "            ],\n",
    "            \"needs_user_input\": False\n",
    "        }\n",
    "\n",
    "#######################################\n",
    "# Initialize the vector search engine\n",
    "#######################################\n",
    "\n",
    "# TODO: Configure your vector store parameters\n",
    "VECTOR_SEARCH_ENDPOINT = \"hackathon_search\"  # Replace with your endpoint\n",
    "VECTOR_INDEX_NAME = \"workspace.default.benefit_search\"  # Replace with your index\n",
    "\n",
    "vector_store = DatabricksVectorSearch(\n",
    "    endpoint=VECTOR_SEARCH_ENDPOINT,\n",
    "    index_name=VECTOR_INDEX_NAME,\n",
    "    columns=[\"plan_id\", \"contract_id\"]  # Columns to retrieve\n",
    ")\n",
    "\n",
    "#######################################\n",
    "# Define the clarification agent\n",
    "#######################################\n",
    "\n",
    "def clarification_agent(state):\n",
    "    prompt = \"Based on the conversation history, ask the user for the necessary information to find a suitable Medicare plan. Be specific about what you need (e.g., age, zip code, health conditions, current prescriptions). Be conversational and helpful.\"\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: state[\"messages\"] + [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    clarification_chain = preprocessor | llm\n",
    "    response = clarification_chain.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": response.content,\n",
    "                \"name\": \"Clarification\",\n",
    "            }\n",
    "        ],\n",
    "        \"needs_user_input\": True  # Flag to indicate we need user response\n",
    "    }\n",
    "\n",
    "#######################################\n",
    "# Define the RAG agent for plan retrieval\n",
    "#######################################\n",
    "\n",
    "def rag_agent(state):\n",
    "    # Extract user requirements from conversation\n",
    "    messages = state.get(\"messages\", [])\n",
    "    \n",
    "    # Build search query from user information\n",
    "    user_info = []\n",
    "    search_query = \"\"\n",
    "    \n",
    "    # Parse messages to extract user requirements\n",
    "    for msg in messages:\n",
    "        if msg.get(\"role\") == \"user\":\n",
    "            user_info.append(msg.get(\"content\", \"\"))\n",
    "    \n",
    "    # Combine user information to create search query\n",
    "    search_query = \" \".join(user_info)\n",
    "    \n",
    "    try:\n",
    "        # Retrieve relevant plans from vector store\n",
    "        retriever = vector_store.as_retriever(\n",
    "            search_kwargs={\n",
    "                \"k\": 10,  # Number of plans to retrieve\n",
    "                \"filters\": {}  # Add filters if needed based on user requirements\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        relevant_plans = retriever.get_relevant_documents(search_query)\n",
    "        \n",
    "        # Format retrieved plans\n",
    "        if relevant_plans:\n",
    "            plans_info = []\n",
    "            contract_ids = []\n",
    "\n",
    "            for doc in relevant_plans:\n",
    "                plan_data = doc.metadata\n",
    "                contract_id = plan_data.get(\"contract_id\", \"N/A\")\n",
    "                \n",
    "                plans_info.append(f\"Contract id: {contract_id}\")\n",
    "                if contract_id != \"N/A\":\n",
    "                    contract_ids.append(contract_id)\n",
    "            \n",
    "            retrieved_context = f\"Found {len(contract_ids)} Medicare plans matching your requirements:\\n\\n\" + \"\\n\".join(plans_info)\n",
    "\n",
    "            return {\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"assistant\", \n",
    "                        \"content\": f\"{retrieved_context}\\n\\nI'll now get detailed benefit information for these plans to help you choose the best one.\",\n",
    "                        \"name\": \"RAG\",\n",
    "                    }\n",
    "                ],\n",
    "                \"retrieved_plans\": [doc.metadata for doc in relevant_plans],\n",
    "                \"contract_ids\": contract_ids,  # Store just the plan IDs for Genie\n",
    "                \"needs_user_input\": False\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": \"I couldn't find any Medicare plans matching your specific requirements in our database. Could you please provide more details about your location or adjust your criteria?\",\n",
    "                        \"name\": \"RAG\",\n",
    "                    }\n",
    "                ],\n",
    "                \"retrieved_plans\": [],\n",
    "                \"contract_ids\": [],\n",
    "                \"needs_user_input\": True  # Ask for more info\n",
    "            }\n",
    "    except Exception as e:\n",
    "        # Fallback if RAG fails\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": f\"I encountered an issue retrieving Medicare plans from our database: {str(e)}. Let me route you to our Genie agent for direct assistance.\",\n",
    "                    \"name\": \"RAG\",\n",
    "                }\n",
    "            ],\n",
    "            \"retrieved_plans\": [],\n",
    "            \"contract_ids\": [],\n",
    "            \"needs_user_input\": False\n",
    "        }\n",
    "\n",
    "\n",
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "\n",
    "# TODO: Replace with your model serving endpoint\n",
    "# multi-agent Genie works best with claude 3.7 or gpt 4o models.\n",
    "LLM_ENDPOINT_NAME = \"databricks-llama-4-maverick\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "#############################\n",
    "# Define the supervisor agent\n",
    "#############################\n",
    "\n",
    "# TODO update the max number of iterations between supervisor and worker nodes\n",
    "# before returning to the user\n",
    "MAX_ITERATIONS = 5\n",
    "\n",
    "worker_descriptions = {\n",
    "    \"Genie\": genie_agent_description,\n",
    "    \"Clarification\": \"This agent help clarify the request of the user so that all needed information are provided.\",\n",
    "    \"RAG\": \"This agent retrieves specific Medicare plan IDs and details from the vector database based on user requirements.\",\n",
    "\n",
    "}\n",
    "\n",
    "formatted_descriptions = \"\\n\".join(\n",
    "    f\"- {name}: {desc}\" for name, desc in worker_descriptions.items()\n",
    ")\n",
    "\n",
    "system_prompt = f\"\"\"You are a supervisor agent. Your job is to route user requests to the appropriate worker agent or to a clarification agent if more information is needed.\n",
    "\n",
    "The available workers are:\n",
    "{formatted_descriptions}\n",
    "\n",
    "**Required workflow for Medicare plan recommendations:**\n",
    "\n",
    "1. **Information Gathering**: If the user hasn't provided essential information (age/Medicare eligibility, location, health conditions, prescriptions, budget), route to 'Clarification'\n",
    "\n",
    "2. **Plan Retrieval**: If user has provided sufficient information but no plans have been retrieved yet, route to 'RAG' to search for relevant Medicare plans\n",
    "\n",
    "3. **Benefit Analysis**: If plans have been retrieved (check for contract_ids in state), route to 'Genie' to get detailed benefit information and recommendations\n",
    "\n",
    "4. **Completion**: If the user has received both plan options AND detailed benefit analysis, respond with 'FINISH'\n",
    "\n",
    "**Current State Analysis:**\n",
    "- Check if 'contract_ids' exists and has values - this means RAG has retrieved plans\n",
    "- Check if Genie has provided detailed benefit analysis\n",
    "- Look at the conversation flow to determine the next logical step\n",
    "\n",
    "**Important Rules:**\n",
    "- Never route to the same agent consecutively unless there was an error\n",
    "- Always follow the logical progression: Clarification → RAG → Genie → FINISH\n",
    "- If contract_ids exist but no detailed analysis has been done, route to Genie\n",
    "- Only FINISH when both plan retrieval AND benefit analysis are complete\n",
    "\n",
    "Choose the next step based on the current state and conversation history.\n",
    "\"\"\"\n",
    "\n",
    "options = [\"FINISH\", \"Clarification\"] + list(worker_descriptions.keys())\n",
    "FINISH = {\"next_node\": \"FINISH\"}\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    count = state.get(\"iteration_count\", 0) + 1\n",
    "    if count > MAX_ITERATIONS:\n",
    "        return FINISH\n",
    "    \n",
    "    class nextNode(BaseModel):\n",
    "        next_node: Literal[tuple(options)]\n",
    "\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    )\n",
    "    supervisor_chain = preprocessor | llm.with_structured_output(nextNode)\n",
    "    next_node = supervisor_chain.invoke(state).next_node\n",
    "    \n",
    "    # if routed back to the same node, exit the loop\n",
    "    if state.get(\"next_node\") == next_node:\n",
    "        return FINISH\n",
    "    return {\n",
    "        \"iteration_count\": count,\n",
    "        \"next_node\": next_node,\n",
    "        \"needs_user_input\": False\n",
    "    }\n",
    "\n",
    "#######################################\n",
    "# Define our multiagent graph structure\n",
    "#######################################\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": result[\"messages\"][-1].content,\n",
    "                \"name\": name,\n",
    "            }\n",
    "        ],\n",
    "        \"needs_user_input\": False\n",
    "    }\n",
    "\n",
    "def should_continue_or_end(state):\n",
    "    \"\"\"Decide whether to continue routing or end based on state\"\"\"\n",
    "    if state.get(\"needs_user_input\", False):\n",
    "        return \"END\"  # Stop here so user can respond to clarification\n",
    "    return \"supervisor\"  # Continue routing\n",
    "\n",
    "class AgentState(ChatAgentState):\n",
    "    next_node: str\n",
    "    iteration_count: int\n",
    "    needs_user_input: bool = False\n",
    "    retrieved_plans: list = []\n",
    "    contract_ids: list = []\n",
    "\n",
    "\n",
    "genie_node = functools.partial(agent_node, agent=enhanced_genie_agent, name=\"Genie\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Genie\", enhanced_genie_agent)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)\n",
    "workflow.add_node(\"Clarification\", clarification_agent)\n",
    "workflow.add_node(\"RAG\", rag_agent)\n",
    "\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "# - Genie and RAG always goes back to supervisor to check if more is needed\n",
    "# - Clarification can either go to END (for user input) or back to supervisor\n",
    "workflow.add_edge(\"Genie\", \"supervisor\")\n",
    "workflow.add_edge(\"RAG\", \"supervisor\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"Clarification\",\n",
    "    should_continue_or_end,\n",
    "    {\n",
    "        \"END\": END,\n",
    "        \"supervisor\": \"supervisor\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Let the supervisor decide which next node to go to\n",
    "conditional_edges = {k: k for k in worker_descriptions.keys()}\n",
    "conditional_edges[\"Clarification\"] = \"Clarification\"\n",
    "conditional_edges[\"FINISH\"] = END\n",
    "\n",
    "# Let the supervisor decide which next node to go\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x: x[\"next_node\"],\n",
    "    conditional_edges\n",
    ")\n",
    "multi_agent = workflow.compile()\n",
    "\n",
    "###################################\n",
    "# Wrap our multi-agent in ChatAgent\n",
    "###################################\n",
    "\n",
    "\n",
    "class LangGraphChatAgent(ChatAgent):\n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        request = {\n",
    "            \"messages\": [m.model_dump_compat(exclude_none=True) for m in messages]\n",
    "        }\n",
    "\n",
    "        messages = []\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                new_messages = node_data.get(\"messages\", [])\n",
    "                if new_messages:\n",
    "                    messages.extend(\n",
    "                        ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "                    )\n",
    "                    # If this is a clarification request, return immediately to allow user response\n",
    "                    if node_data.get(\"needs_user_input\", False):\n",
    "                        break\n",
    "        return ChatAgentResponse(messages=messages)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        request = {\n",
    "            \"messages\": [m.model_dump_compat(exclude_none=True) for m in messages]\n",
    "        }\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                new_messages = node_data.get(\"messages\", [])\n",
    "                if new_messages:\n",
    "                    yield from (\n",
    "                        ChatAgentChunk(**{\"delta\": msg})\n",
    "                        for msg in node_data.get(\"messages\", [])\n",
    "                    )\n",
    "                    # If this is a clarification request, stop streaming to allow user response\n",
    "                    if node_data.get(\"needs_user_input\", False):\n",
    "                        break\n",
    "\n",
    "\n",
    "# Create the agent object, and specify it as the agent object to use when\n",
    "# loading the agent back for inference via mlflow.models.set_model()\n",
    "mlflow.langchain.autolog()\n",
    "AGENT = LangGraphChatAgent(multi_agent)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be561876-d3f3-465c-905c-5dd9f2db920f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Test the agent with a simple user message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a275b98-eb2e-4028-9603-018ec5825ca4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatAgentResponse(messages=[ChatAgentMessage(role='assistant', content=\"Teeth routine cleaning is so important at any age! I'm happy to help you find a suitable option.\\n\\nSince you mentioned you don't have dental insurance, I'm assuming you're looking for affordable options. However, I did notice you mentioned you're 70 years old. That got me thinking - are you aware that Original Medicare (Part A and Part B) doesn't typically cover routine dental care, including teeth cleanings?\\n\\nBut, some Medicare Advantage plans (also known as Medicare Part C) may offer additional benefits, including dental coverage! If you're interested in exploring this option, I'd be happy to help you find a plan that suits your needs.\\n\\nTo get started, could you please share your zip code in Dutchess County? This will help me narrow down the available Medicare Advantage plans in your area.\\n\\nAlso, just to confirm, you mentioned you don't have any other health conditions. That's great! However, I do need to ask: are you currently taking any prescription medications? Knowing this will help me better understand your needs when looking for a Medicare Advantage plan.\\n\\nLastly, are you currently enrolled in Original Medicare (Part A and Part B)? This information will also help me guide you in finding a suitable plan.\\n\\nLet's chat more about this, and I'll do my best to help you find a plan that fits your needs and budget!\", name='Clarification', id='8634b4a0-5fff-4b8d-85e0-56358df0fb45', tool_calls=None, tool_call_id=None, attachments=None)], finish_reason=None, custom_outputs=None, usage=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/databricks.mlflow.trace": "\"tr-1fd802fa34224f94bea26267d88e9ca5\"",
      "text/plain": [
       "Trace(request_id=tr-1fd802fa34224f94bea26267d88e9ca5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agent import AGENT\n",
    "\n",
    "input_example = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I am 70 years old and live in dutchess county. I am looking for a teeth routine cleaning. I do not have any other health conditions. I do not have dental insurance.\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "AGENT.predict(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efb13c1e-5a83-4aa7-8e6a-cc6c4fdfa828",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Set the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75432653-c82e-4c14-bff3-c1f4ee2ca90f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dbruntime.databricks_repl_context import get_context\n",
    "\n",
    "# TODO: set secret_scope_name and secret_key_name to access your PAT\n",
    "secret_scope_name = \"hackathon\"\n",
    "secret_key_name = \"pat\"\n",
    "\n",
    "os.environ[\"DB_MODEL_SERVING_HOST_URL\"] = \"https://dbc-05bab63c-84b8.cloud.databricks.com/browse/folders/workspace?o=806146813099306\"\n",
    "assert os.environ[\"DB_MODEL_SERVING_HOST_URL\"] is not None\n",
    "os.environ[\"DATABRICKS_GENIE_PAT\"] = dbutils.secrets.get(\n",
    "    scope=secret_scope_name, key=secret_key_name\n",
    ")\n",
    "assert os.environ[\"DATABRICKS_GENIE_PAT\"] is not None, (\n",
    "    \"The DATABRICKS_GENIE_PAT was not properly set to the PAT secret\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6c37bd3-a098-49d8-90c3-ee2cbbdedcca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Register the model with mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f56a3cd7-8df3-4cfd-bbcc-b042ab4c4f02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 21:22:40 INFO mlflow.pyfunc: Predicting on input example to validate output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc70b82f4e764ebb88c1c999f58448af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.databricks.v1+autoreload_discoverability": "{\"mode\":\"first_should_hint\"}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "import mlflow\n",
    "from agent import GENIE_SPACE_ID, LLM_ENDPOINT_NAME\n",
    "from databricks_langchain import UnityCatalogTool, VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import (\n",
    "    DatabricksFunction,\n",
    "    DatabricksGenieSpace,\n",
    "    DatabricksServingEndpoint,\n",
    ")\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "# TODO: Manually include underlying resources if needed. See the TODO in the markdown above for more information.\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME),\n",
    "    DatabricksGenieSpace(genie_space_id=GENIE_SPACE_ID),\n",
    "#   DatabricksSQLWarehouse(warehouse_id=\"your_warehouse_id\"),\n",
    "#   DatabricksTable(table_name=\"your_table_name\"),\n",
    "]\n",
    "\n",
    "# for tool in tools:\n",
    "#     if isinstance(tool, VectorSearchRetrieverTool):\n",
    "#         resources.extend(tool.resources)\n",
    "#     elif isinstance(tool, UnityCatalogTool):\n",
    "#         resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        input_example=input_example,\n",
    "        extra_pip_requirements=[f\"databricks-connect=={get_distribution('databricks-connect').version}\"],\n",
    "        resources=resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eeab4c70-d54a-4cdb-bde3-5f9d8c808d97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Test the deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "314d87ce-fac5-4622-9825-5d2b8b80c2cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9596d05be39b4629b31099bc6ab71d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 21:25:27 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c7f75911934c9f9a80dc2ad05711f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 21:25:29 INFO mlflow.utils.virtualenv: Creating a new environment in /tmp/virtualenv_envs_ce907db7/mlflow-3e34192403d42e40bc5d898d008b8ab35e3e7faf with python version 3.11.10 using uv\n",
      "Using CPython 3.11.10 interpreter at: \u001b[36m/usr/bin/python3.11\u001b[39m\n",
      "Creating virtual environment at: \u001b[36m/tmp/virtualenv_envs_ce907db7/mlflow-3e34192403d42e40bc5d898d008b8ab35e3e7faf\u001b[39m\n",
      "Activate with: \u001b[32msource /tmp/virtualenv_envs_ce907db7/mlflow-3e34192403d42e40bc5d898d008b8ab35e3e7faf/bin/activate\u001b[39m\n",
      "2025/06/09 21:25:31 INFO mlflow.utils.virtualenv: Installing dependencies\n",
      "\u001b[2mUsing Python 3.11.10 environment at: /tmp/virtualenv_envs_ce907db7/mlflow-3e34192403d42e40bc5d898d008b8ab35e3e7faf\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m3 packages\u001b[0m \u001b[2min 87ms\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m setuptools \u001b[2m(1.2MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pip \u001b[2m(1.7MiB)\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pip\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m setuptools\n",
      "\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 199ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 33ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==24.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==75.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwheel\u001b[0m\u001b[2m==0.38.4\u001b[0m\n",
      "\u001b[2mUsing Python 3.11.10 environment at: /tmp/virtualenv_envs_ce907db7/mlflow-3e34192403d42e40bc5d898d008b8ab35e3e7faf\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m159 packages\u001b[0m \u001b[2min 1.65s\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m grpcio \u001b[2m(5.8MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m aiohttp \u001b[2m(1.6MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pygments \u001b[2m(1.2MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m mlflow \u001b[2m(27.7MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pillow \u001b[2m(4.4MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m sqlalchemy \u001b[2m(3.1MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m databricks-connect \u001b[2m(2.3MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m mlflow-skinny \u001b[2m(6.0MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m botocore \u001b[2m(13.0MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m zstandard \u001b[2m(5.2MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m scipy \u001b[2m(33.6MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m cython \u001b[2m(1.8MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pydantic-core \u001b[2m(1.9MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m cryptography \u001b[2m(4.3MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m numpy \u001b[2m(17.4MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m jedi \u001b[2m(1.5MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m kiwisolver \u001b[2m(1.4MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m fonttools \u001b[2m(4.7MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pyarrow \u001b[2m(36.2MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m matplotlib \u001b[2m(8.2MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pandas \u001b[2m(11.5MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m tiktoken \u001b[2m(1.1MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m langchain-community \u001b[2m(2.4MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m scikit-learn \u001b[2m(12.3MiB)\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m tiktoken\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pygments\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m kiwisolver\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m aiohttp\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m cython\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pydantic-core\n",
      "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m psutil\u001b[2m==5.9.0\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m databricks-connect\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m sqlalchemy\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pillow\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m cryptography\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m fonttools\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m zstandard\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m langchain-community\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m grpcio\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m matplotlib\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m mlflow-skinny\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pandas\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m jedi\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m numpy\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m scikit-learn\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m mlflow\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m scipy\n",
      "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m psutil\u001b[2m==5.9.0\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m botocore\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pyarrow\n",
      "\u001b[2mPrepared \u001b[1m158 packages\u001b[0m \u001b[2min 8.10s\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m158 packages\u001b[0m \u001b[2min 799ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohappyeyeballs\u001b[0m\u001b[2m==2.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohttp\u001b[0m\u001b[2m==3.12.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohttp-retry\u001b[0m\u001b[2m==2.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiosignal\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1malembic\u001b[0m\u001b[2m==1.16.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mazure-core\u001b[0m\u001b[2m==1.34.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mazure-storage-blob\u001b[0m\u001b[2m==12.26.0b1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mazure-storage-file-datalake\u001b[0m\u001b[2m==12.21.0b1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mblinker\u001b[0m\u001b[2m==1.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mboto3\u001b[0m\u001b[2m==1.38.33\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbotocore\u001b[0m\u001b[2m==1.38.33\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcachetools\u001b[0m\u001b[2m==5.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.4.26\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcffi\u001b[0m\u001b[2m==1.17.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcloudpickle\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcryptography\u001b[0m\u001b[2m==45.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcython\u001b[0m\u001b[2m==0.29.32\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatabricks-agents\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatabricks-ai-bridge\u001b[0m\u001b[2m==0.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatabricks-connect\u001b[0m\u001b[2m==16.1.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatabricks-langchain\u001b[0m\u001b[2m==0.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatabricks-sdk\u001b[0m\u001b[2m==0.56.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatabricks-vectorsearch\u001b[0m\u001b[2m==0.56\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdataclasses-json\u001b[0m\u001b[2m==0.6.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdeprecation\u001b[0m\u001b[2m==2.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdocker\u001b[0m\u001b[2m==7.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastapi\u001b[0m\u001b[2m==0.115.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mflask\u001b[0m\u001b[2m==3.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.58.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfrozenlist\u001b[0m\u001b[2m==1.6.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgitdb\u001b[0m\u001b[2m==4.0.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgitpython\u001b[0m\u001b[2m==3.1.44\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-api-core\u001b[0m\u001b[2m==2.25.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-auth\u001b[0m\u001b[2m==2.40.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-cloud-core\u001b[0m\u001b[2m==2.4.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-cloud-storage\u001b[0m\u001b[2m==2.18.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-crc32c\u001b[0m\u001b[2m==1.7.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-resumable-media\u001b[0m\u001b[2m==2.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogleapis-common-protos\u001b[0m\u001b[2m==1.70.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgraphene\u001b[0m\u001b[2m==3.4.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgraphql-core\u001b[0m\u001b[2m==3.2.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgraphql-relay\u001b[0m\u001b[2m==3.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgreenlet\u001b[0m\u001b[2m==3.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.73.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio-status\u001b[0m\u001b[2m==1.71.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgunicorn\u001b[0m\u001b[2m==23.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx-sse\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mimportlib-metadata\u001b[0m\u001b[2m==8.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==8.25.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1misodate\u001b[0m\u001b[2m==0.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mitsdangerous\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjmespath\u001b[0m\u001b[2m==1.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonpatch\u001b[0m\u001b[2m==1.33\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonpointer\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain\u001b[0m\u001b[2m==0.3.25\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-community\u001b[0m\u001b[2m==0.3.24\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-core\u001b[0m\u001b[2m==0.3.64\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-text-splitters\u001b[0m\u001b[2m==0.3.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanggraph\u001b[0m\u001b[2m==0.3.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanggraph-checkpoint\u001b[0m\u001b[2m==2.0.26\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanggraph-prebuilt\u001b[0m\u001b[2m==0.1.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanggraph-sdk\u001b[0m\u001b[2m==0.1.70\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangsmith\u001b[0m\u001b[2m==0.3.45\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmako\u001b[0m\u001b[2m==1.3.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown\u001b[0m\u001b[2m==3.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarshmallow\u001b[0m\u001b[2m==3.26.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.1.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmlflow\u001b[0m\u001b[2m==2.22.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmlflow-skinny\u001b[0m\u001b[2m==2.22.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmultidict\u001b[0m\u001b[2m==6.4.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmypy-extensions\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-api\u001b[0m\u001b[2m==1.34.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-sdk\u001b[0m\u001b[2m==1.34.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-semantic-conventions\u001b[0m\u001b[2m==0.55b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1morjson\u001b[0m\u001b[2m==3.10.18\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mormsgpack\u001b[0m\u001b[2m==1.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==24.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==1.5.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.51\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpropcache\u001b[0m\u001b[2m==0.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mproto-plus\u001b[0m\u001b[2m==1.26.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==5.29.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==5.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpy4j\u001b[0m\u001b[2m==0.10.9.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==14.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1\u001b[0m\u001b[2m==0.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1-modules\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpycparser\u001b[0m\u001b[2m==2.22\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-settings\u001b[0m\u001b[2m==2.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2024.11.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests-toolbelt\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrsa\u001b[0m\u001b[2m==4.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1ms3transfer\u001b[0m\u001b[2m==0.13.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.16.0rc2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msmmap\u001b[0m\u001b[2m==5.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msqlalchemy\u001b[0m\u001b[2m==2.0.41\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msqlparse\u001b[0m\u001b[2m==0.5.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.46.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtabulate\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtenacity\u001b[0m\u001b[2m==9.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtiktoken\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.14.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspect\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1munitycatalog-ai\u001b[0m\u001b[2m==0.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1munitycatalog-client\u001b[0m\u001b[2m==0.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1munitycatalog-langchain\u001b[0m\u001b[2m==0.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.34.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.13\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwerkzeug\u001b[0m\u001b[2m==3.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1myarl\u001b[0m\u001b[2m==1.20.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mzipp\u001b[0m\u001b[2m==3.23.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mzstandard\u001b[0m\u001b[2m==0.23.0\u001b[0m\n",
      "2025/06/09 21:25:42 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /tmp/virtualenv_envs_ce907db7/mlflow-3e34192403d42e40bc5d898d008b8ab35e3e7faf/bin/activate && python -c \"\"']'\n",
      "2025/06/09 21:25:42 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /tmp/virtualenv_envs_ce907db7/mlflow-3e34192403d42e40bc5d898d008b8ab35e3e7faf/bin/activate && python /local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/pyfunc/_mlflow_pyfunc_backend_predict.py --model-uri file:///local_disk0/user_tmp_data/spark-2a53b0fd-3a1d-4607-a075-be/tmpouegxh04/agent --content-type json --input-path /local_disk0/user_tmp_data/spark-2a53b0fd-3a1d-4607-a075-be/tmpw5x6ng5n/input.json']'\n",
      "Mon Jun  9 21:25:53 2025 Connection to spark from PID  43570\n",
      "Mon Jun  9 21:25:53 2025 Initialized gateway on port 40909\n",
      "Mon Jun  9 21:25:53 2025 Connected to spark.\n",
      "/local_disk0/user_tmp_data/spark-2a53b0fd-3a1d-4607-a075-be/tmpouegxh04/agent/agent.py:205: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  relevant_plans = retriever.get_relevant_documents(search_query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:132)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:132)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:129)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:129)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:715)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:435)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:435)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:466)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:757)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:83)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:83)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:83)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:83)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:735)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:926)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$4(Chauffeur.scala:952)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:951)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:1006)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:777)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1037)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:957)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:552)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:522)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:806)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:52)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:806)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:769)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:751)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$15(ActivityContextFactory.scala:283)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:52)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:283)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:522)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:415)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:132)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:132)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:129)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:129)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:715)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:435)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:435)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:466)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:757)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:83)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:83)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:83)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:83)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:735)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:926)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$4(Chauffeur.scala:952)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:951)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:1006)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:777)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:510)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:616)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:643)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:611)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:519)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:511)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:475)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:146)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1037)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:957)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:552)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:522)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:806)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:52)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:806)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:769)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:751)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$15(ActivityContextFactory.scala:283)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:52)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:283)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:522)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:415)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:110)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:110)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:45)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:92)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data=input_example,\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7155b22-1cdd-4331-b294-26549faf4630",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'workspace.models.first-try-model' already exists. Creating a new version of this model...\n",
      "2025/06/09 21:27:56 WARNING mlflow.store._unity_catalog.registry.rest_store: Unable to get model version source run's workspace ID from request headers. No run link will be recorded for the model version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
       "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)\n",
       "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/store/_unity_catalog/registry/rest_store.py:711\u001b[0m, in \u001b[0;36mUcModelRegistryStore._local_model_dir\u001b[0;34m(self, source, local_model_path)\u001b[0m\n",
       "\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
       "\u001b[0;32m--> 711\u001b[0m     local_model_dir \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39martifacts\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n",
       "\u001b[1;32m    712\u001b[0m         artifact_uri\u001b[38;5;241m=\u001b[39msource, tracking_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracking_uri\n",
       "\u001b[1;32m    713\u001b[0m     )\n",
       "\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
       "\n",
       "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/artifacts/__init__.py:80\u001b[0m, in \u001b[0;36mdownload_artifacts\u001b[0;34m(artifact_uri, run_id, artifact_path, dst_path, tracking_uri)\u001b[0m\n",
       "\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artifact_uri \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
       "\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _download_artifact_from_uri(artifact_uri, output_path\u001b[38;5;241m=\u001b[39mdst_path)\n",
       "\u001b[1;32m     82\u001b[0m artifact_path \u001b[38;5;241m=\u001b[39m artifact_path \u001b[38;5;28;01mif\u001b[39;00m artifact_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\n",
       "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/tracking/artifact_utils.py:116\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[0;34m(artifact_uri, output_path, lineage_header_info)\u001b[0m\n",
       "\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n",
       "\u001b[1;32m    112\u001b[0m         artifact_path\u001b[38;5;241m=\u001b[39martifact_path,\n",
       "\u001b[1;32m    113\u001b[0m         dst_path\u001b[38;5;241m=\u001b[39moutput_path,\n",
       "\u001b[1;32m    114\u001b[0m         lineage_header_info\u001b[38;5;241m=\u001b[39mlineage_header_info,\n",
       "\u001b[1;32m    115\u001b[0m     )\n",
       "\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mdownload_artifacts(artifact_path\u001b[38;5;241m=\u001b[39martifact_path, dst_path\u001b[38;5;241m=\u001b[39moutput_path)\n",
       "\n",
       "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/store/artifact/local_artifact_repo.py:91\u001b[0m, in \u001b[0;36mLocalArtifactRepository.download_artifacts\u001b[0;34m(self, artifact_path, dst_path)\u001b[0m\n",
       "\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(local_artifact_path):\n",
       "\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_artifact_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
       "\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(local_artifact_path)\n",
       "\n",
       "\u001b[0;31mOSError\u001b[0m: No such file or directory: 'workspace.models.first-try-model'\n",
       "\n",
       "The above exception was the direct cause of the following exception:\n",
       "\n",
       "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)\n",
       "File \u001b[0;32m<command-6472415868083958>, line 10\u001b[0m\n",
       "\u001b[1;32m      7\u001b[0m UC_MODEL_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcatalog\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschema\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# register the model to UC\u001b[39;00m\n",
       "\u001b[0;32m---> 10\u001b[0m uc_registered_model_info \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mregister_model(\n",
       "\u001b[1;32m     11\u001b[0m     model_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkspace.models.first-try-model\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mUC_MODEL_NAME\n",
       "\u001b[1;32m     12\u001b[0m )\n",
       "\n",
       "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/tracking/_model_registry/fluent.py:80\u001b[0m, in \u001b[0;36mregister_model\u001b[0;34m(model_uri, name, await_registration_for, tags)\u001b[0m\n",
       "\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregister_model\u001b[39m(\n",
       "\u001b[1;32m     21\u001b[0m     model_uri,\n",
       "\u001b[1;32m     22\u001b[0m     name,\n",
       "\u001b[0;32m   (...)\u001b[0m\n",
       "\u001b[1;32m     25\u001b[0m     tags: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "\u001b[1;32m     26\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModelVersion:\n",
       "\u001b[1;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a new model version in model registry for the model files specified by ``model_uri``.\u001b[39;00m\n",
       "\u001b[1;32m     28\u001b[0m \n",
       "\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    Note that this method assumes the model registry backend URI is the same as that of the\u001b[39;00m\n",
       "\u001b[0;32m   (...)\u001b[0m\n",
       "\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m        Version: 1\u001b[39;00m\n",
       "\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
       "\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _register_model(\n",
       "\u001b[1;32m     81\u001b[0m         model_uri\u001b[38;5;241m=\u001b[39mmodel_uri, name\u001b[38;5;241m=\u001b[39mname, await_registration_for\u001b[38;5;241m=\u001b[39mawait_registration_for, tags\u001b[38;5;241m=\u001b[39mtags\n",
       "\u001b[1;32m     82\u001b[0m     )\n",
       "\n",
       "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/tracking/_model_registry/fluent.py:114\u001b[0m, in \u001b[0;36m_register_model\u001b[0;34m(model_uri, name, await_registration_for, tags, local_model_path)\u001b[0m\n",
       "\u001b[1;32m    111\u001b[0m     source \u001b[38;5;241m=\u001b[39m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mget_underlying_uri(model_uri)\n",
       "\u001b[1;32m    112\u001b[0m     (run_id, _) \u001b[38;5;241m=\u001b[39m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mparse_runs_uri(model_uri)\n",
       "\u001b[0;32m--> 114\u001b[0m create_version_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39m_create_model_version(\n",
       "\u001b[1;32m    115\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n",
       "\u001b[1;32m    116\u001b[0m     source\u001b[38;5;241m=\u001b[39msource,\n",
       "\u001b[1;32m    117\u001b[0m     run_id\u001b[38;5;241m=\u001b[39mrun_id,\n",
       "\u001b[1;32m    118\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n",
       "\u001b[1;32m    119\u001b[0m     await_creation_for\u001b[38;5;241m=\u001b[39mawait_registration_for,\n",
       "\u001b[1;32m    120\u001b[0m     local_model_path\u001b[38;5;241m=\u001b[39mlocal_model_path,\n",
       "\u001b[1;32m    121\u001b[0m )\n",
       "\u001b[1;32m    122\u001b[0m eprint(\n",
       "\u001b[1;32m    123\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated version \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcreate_version_response\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m of model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m    124\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcreate_version_response\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m    125\u001b[0m )\n",
       "\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m create_version_response\n",
       "\n",
       "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/tracking/client.py:4105\u001b[0m, in \u001b[0;36mMlflowClient._create_model_version\u001b[0;34m(self, name, source, run_id, tags, run_link, description, await_creation_for, local_model_path)\u001b[0m\n",
       "\u001b[1;32m   4097\u001b[0m     \u001b[38;5;66;03m# NOTE: we can't easily delete the target temp location due to the async nature\u001b[39;00m\n",
       "\u001b[1;32m   4098\u001b[0m     \u001b[38;5;66;03m# of the model version creation - printing to let the user know.\u001b[39;00m\n",
       "\u001b[1;32m   4099\u001b[0m     eprint(\n",
       "\u001b[1;32m   4100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Source model files were copied to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_source\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m   4101\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the model registry workspace. You may want to delete the files once the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m   4102\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model version is in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREADY\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m status. You can also find this location in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m   4103\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `source` field of the created model version. ===\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m   4104\u001b[0m     )\n",
       "\u001b[0;32m-> 4105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_registry_client()\u001b[38;5;241m.\u001b[39mcreate_model_version(\n",
       "\u001b[1;32m   4106\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n",
       "\u001b[1;32m   4107\u001b[0m     source\u001b[38;5;241m=\u001b[39mnew_source,\n",
       "\u001b[1;32m   4108\u001b[0m     run_id\u001b[38;5;241m=\u001b[39mrun_id,\n",
       "\u001b[1;32m   4109\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n",
       "\u001b[1;32m   4110\u001b[0m     run_link\u001b[38;5;241m=\u001b[39mrun_link,\n",
       "\u001b[1;32m   4111\u001b[0m     description\u001b[38;5;241m=\u001b[39mdescription,\n",
       "\u001b[1;32m   4112\u001b[0m     await_creation_for\u001b[38;5;241m=\u001b[39mawait_creation_for,\n",
       "\u001b[1;32m   4113\u001b[0m     local_model_path\u001b[38;5;241m=\u001b[39mlocal_model_path,\n",
       "\u001b[1;32m   4114\u001b[0m )\n",
       "\n",
       "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/tracking/_model_registry/client.py:229\u001b[0m, in \u001b[0;36mModelRegistryClient.create_model_version\u001b[0;34m(self, name, source, run_id, tags, run_link, description, await_creation_for, local_model_path)\u001b[0m\n",
       "\u001b[1;32m    227\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m _get_arg_names(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mcreate_model_version)\n",
       "\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_model_path\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_names:\n",
       "\u001b[0;32m--> 229\u001b[0m     mv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mcreate_model_version(\n",
       "\u001b[1;32m    230\u001b[0m         name,\n",
       "\u001b[1;32m    231\u001b[0m         source,\n",
       "\u001b[1;32m    232\u001b[0m         run_id,\n",
       "\u001b[1;32m    233\u001b[0m         tags,\n",
       "\u001b[1;32m    234\u001b[0m         run_link,\n",
       "\u001b[1;32m    235\u001b[0m         description,\n",
       "\u001b[1;32m    236\u001b[0m         local_model_path\u001b[38;5;241m=\u001b[39mlocal_model_path,\n",
       "\u001b[1;32m    237\u001b[0m     )\n",
       "\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
       "\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# Fall back to calling create_model_version without\u001b[39;00m\n",
       "\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# local_model_path since old model registry store implementations may not\u001b[39;00m\n",
       "\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# support the local_model_path argument.\u001b[39;00m\n",
       "\u001b[1;32m    242\u001b[0m     mv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mcreate_model_version(name, source, run_id, tags, run_link, description)\n",
       "\n",
       "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/store/_unity_catalog/registry/rest_store.py:791\u001b[0m, in \u001b[0;36mUcModelRegistryStore.create_model_version\u001b[0;34m(self, name, source, run_id, tags, run_link, description, local_model_path)\u001b[0m\n",
       "\u001b[1;32m    789\u001b[0m     extra_headers \u001b[38;5;241m=\u001b[39m {_DATABRICKS_LINEAGE_ID_HEADER: header_base64}\n",
       "\u001b[1;32m    790\u001b[0m full_name \u001b[38;5;241m=\u001b[39m get_full_name_from_sc(name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspark)\n",
       "\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_model_dir(source, local_model_path) \u001b[38;5;28;01mas\u001b[39;00m local_model_dir:\n",
       "\u001b[1;32m    792\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_model_signature(local_model_dir)\n",
       "\u001b[1;32m    793\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_model_weights_if_not_saved(local_model_dir)\n",
       "\n",
       "File \u001b[0;32m/usr/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n",
       "\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n",
       "\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
       "\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n",
       "\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
       "\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
       "\n",
       "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/store/_unity_catalog/registry/rest_store.py:715\u001b[0m, in \u001b[0;36mUcModelRegistryStore._local_model_dir\u001b[0;34m(self, source, local_model_path)\u001b[0m\n",
       "\u001b[1;32m    711\u001b[0m     local_model_dir \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39martifacts\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n",
       "\u001b[1;32m    712\u001b[0m         artifact_uri\u001b[38;5;241m=\u001b[39msource, tracking_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracking_uri\n",
       "\u001b[1;32m    713\u001b[0m     )\n",
       "\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
       "\u001b[0;32m--> 715\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n",
       "\u001b[1;32m    716\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to download model artifacts from source artifact location \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m    717\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in order to upload them to Unity Catalog. Please ensure \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m    718\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe source artifact location exists and that you can download from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m    719\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit via mlflow.artifacts.download_artifacts()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
       "\u001b[1;32m    720\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
       "\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
       "\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m local_model_dir\n",
       "\n",
       "\u001b[0;31mMlflowException\u001b[0m: Unable to download model artifacts from source artifact location 'workspace.models.first-try-model' in order to upload them to Unity Catalog. Please ensure the source artifact location exists and that you can download from it via mlflow.artifacts.download_artifacts()"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "MlflowException",
        "evalue": "Unable to download model artifacts from source artifact location 'workspace.models.first-try-model' in order to upload them to Unity Catalog. Please ensure the source artifact location exists and that you can download from it via mlflow.artifacts.download_artifacts()"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>MlflowException</span>: Unable to download model artifacts from source artifact location 'workspace.models.first-try-model' in order to upload them to Unity Catalog. Please ensure the source artifact location exists and that you can download from it via mlflow.artifacts.download_artifacts()"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
        "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
        "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/store/_unity_catalog/registry/rest_store.py:711\u001b[0m, in \u001b[0;36mUcModelRegistryStore._local_model_dir\u001b[0;34m(self, source, local_model_path)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 711\u001b[0m     local_model_dir \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39martifacts\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n\u001b[1;32m    712\u001b[0m         artifact_uri\u001b[38;5;241m=\u001b[39msource, tracking_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracking_uri\n\u001b[1;32m    713\u001b[0m     )\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
        "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/artifacts/__init__.py:80\u001b[0m, in \u001b[0;36mdownload_artifacts\u001b[0;34m(artifact_uri, run_id, artifact_path, dst_path, tracking_uri)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artifact_uri \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _download_artifact_from_uri(artifact_uri, output_path\u001b[38;5;241m=\u001b[39mdst_path)\n\u001b[1;32m     82\u001b[0m artifact_path \u001b[38;5;241m=\u001b[39m artifact_path \u001b[38;5;28;01mif\u001b[39;00m artifact_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
        "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/tracking/artifact_utils.py:116\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[0;34m(artifact_uri, output_path, lineage_header_info)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n\u001b[1;32m    112\u001b[0m         artifact_path\u001b[38;5;241m=\u001b[39martifact_path,\n\u001b[1;32m    113\u001b[0m         dst_path\u001b[38;5;241m=\u001b[39moutput_path,\n\u001b[1;32m    114\u001b[0m         lineage_header_info\u001b[38;5;241m=\u001b[39mlineage_header_info,\n\u001b[1;32m    115\u001b[0m     )\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mdownload_artifacts(artifact_path\u001b[38;5;241m=\u001b[39martifact_path, dst_path\u001b[38;5;241m=\u001b[39moutput_path)\n",
        "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/store/artifact/local_artifact_repo.py:91\u001b[0m, in \u001b[0;36mLocalArtifactRepository.download_artifacts\u001b[0;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(local_artifact_path):\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_artifact_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(local_artifact_path)\n",
        "\u001b[0;31mOSError\u001b[0m: No such file or directory: 'workspace.models.first-try-model'",
        "\nThe above exception was the direct cause of the following exception:\n",
        "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
        "File \u001b[0;32m<command-6472415868083958>, line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m UC_MODEL_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcatalog\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mschema\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# register the model to UC\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m uc_registered_model_info \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mregister_model(\n\u001b[1;32m     11\u001b[0m     model_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mworkspace.models.first-try-model\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mUC_MODEL_NAME\n\u001b[1;32m     12\u001b[0m )\n",
        "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/tracking/_model_registry/fluent.py:80\u001b[0m, in \u001b[0;36mregister_model\u001b[0;34m(model_uri, name, await_registration_for, tags)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregister_model\u001b[39m(\n\u001b[1;32m     21\u001b[0m     model_uri,\n\u001b[1;32m     22\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     tags: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     26\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModelVersion:\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a new model version in model registry for the model files specified by ``model_uri``.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    Note that this method assumes the model registry backend URI is the same as that of the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m        Version: 1\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _register_model(\n\u001b[1;32m     81\u001b[0m         model_uri\u001b[38;5;241m=\u001b[39mmodel_uri, name\u001b[38;5;241m=\u001b[39mname, await_registration_for\u001b[38;5;241m=\u001b[39mawait_registration_for, tags\u001b[38;5;241m=\u001b[39mtags\n\u001b[1;32m     82\u001b[0m     )\n",
        "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/tracking/_model_registry/fluent.py:114\u001b[0m, in \u001b[0;36m_register_model\u001b[0;34m(model_uri, name, await_registration_for, tags, local_model_path)\u001b[0m\n\u001b[1;32m    111\u001b[0m     source \u001b[38;5;241m=\u001b[39m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mget_underlying_uri(model_uri)\n\u001b[1;32m    112\u001b[0m     (run_id, _) \u001b[38;5;241m=\u001b[39m RunsArtifactRepository\u001b[38;5;241m.\u001b[39mparse_runs_uri(model_uri)\n\u001b[0;32m--> 114\u001b[0m create_version_response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39m_create_model_version(\n\u001b[1;32m    115\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    116\u001b[0m     source\u001b[38;5;241m=\u001b[39msource,\n\u001b[1;32m    117\u001b[0m     run_id\u001b[38;5;241m=\u001b[39mrun_id,\n\u001b[1;32m    118\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m    119\u001b[0m     await_creation_for\u001b[38;5;241m=\u001b[39mawait_registration_for,\n\u001b[1;32m    120\u001b[0m     local_model_path\u001b[38;5;241m=\u001b[39mlocal_model_path,\n\u001b[1;32m    121\u001b[0m )\n\u001b[1;32m    122\u001b[0m eprint(\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated version \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcreate_version_response\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m of model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcreate_version_response\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m )\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m create_version_response\n",
        "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/tracking/client.py:4105\u001b[0m, in \u001b[0;36mMlflowClient._create_model_version\u001b[0;34m(self, name, source, run_id, tags, run_link, description, await_creation_for, local_model_path)\u001b[0m\n\u001b[1;32m   4097\u001b[0m     \u001b[38;5;66;03m# NOTE: we can't easily delete the target temp location due to the async nature\u001b[39;00m\n\u001b[1;32m   4098\u001b[0m     \u001b[38;5;66;03m# of the model version creation - printing to let the user know.\u001b[39;00m\n\u001b[1;32m   4099\u001b[0m     eprint(\n\u001b[1;32m   4100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Source model files were copied to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_source\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4101\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the model registry workspace. You may want to delete the files once the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4102\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m model version is in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREADY\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m status. You can also find this location in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4103\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `source` field of the created model version. ===\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4104\u001b[0m     )\n\u001b[0;32m-> 4105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_registry_client()\u001b[38;5;241m.\u001b[39mcreate_model_version(\n\u001b[1;32m   4106\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m   4107\u001b[0m     source\u001b[38;5;241m=\u001b[39mnew_source,\n\u001b[1;32m   4108\u001b[0m     run_id\u001b[38;5;241m=\u001b[39mrun_id,\n\u001b[1;32m   4109\u001b[0m     tags\u001b[38;5;241m=\u001b[39mtags,\n\u001b[1;32m   4110\u001b[0m     run_link\u001b[38;5;241m=\u001b[39mrun_link,\n\u001b[1;32m   4111\u001b[0m     description\u001b[38;5;241m=\u001b[39mdescription,\n\u001b[1;32m   4112\u001b[0m     await_creation_for\u001b[38;5;241m=\u001b[39mawait_creation_for,\n\u001b[1;32m   4113\u001b[0m     local_model_path\u001b[38;5;241m=\u001b[39mlocal_model_path,\n\u001b[1;32m   4114\u001b[0m )\n",
        "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/tracking/_model_registry/client.py:229\u001b[0m, in \u001b[0;36mModelRegistryClient.create_model_version\u001b[0;34m(self, name, source, run_id, tags, run_link, description, await_creation_for, local_model_path)\u001b[0m\n\u001b[1;32m    227\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m _get_arg_names(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mcreate_model_version)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_model_path\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_names:\n\u001b[0;32m--> 229\u001b[0m     mv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mcreate_model_version(\n\u001b[1;32m    230\u001b[0m         name,\n\u001b[1;32m    231\u001b[0m         source,\n\u001b[1;32m    232\u001b[0m         run_id,\n\u001b[1;32m    233\u001b[0m         tags,\n\u001b[1;32m    234\u001b[0m         run_link,\n\u001b[1;32m    235\u001b[0m         description,\n\u001b[1;32m    236\u001b[0m         local_model_path\u001b[38;5;241m=\u001b[39mlocal_model_path,\n\u001b[1;32m    237\u001b[0m     )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# Fall back to calling create_model_version without\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# local_model_path since old model registry store implementations may not\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# support the local_model_path argument.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     mv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mcreate_model_version(name, source, run_id, tags, run_link, description)\n",
        "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/store/_unity_catalog/registry/rest_store.py:791\u001b[0m, in \u001b[0;36mUcModelRegistryStore.create_model_version\u001b[0;34m(self, name, source, run_id, tags, run_link, description, local_model_path)\u001b[0m\n\u001b[1;32m    789\u001b[0m     extra_headers \u001b[38;5;241m=\u001b[39m {_DATABRICKS_LINEAGE_ID_HEADER: header_base64}\n\u001b[1;32m    790\u001b[0m full_name \u001b[38;5;241m=\u001b[39m get_full_name_from_sc(name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspark)\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_model_dir(source, local_model_path) \u001b[38;5;28;01mas\u001b[39;00m local_model_dir:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_model_signature(local_model_dir)\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download_model_weights_if_not_saved(local_model_dir)\n",
        "File \u001b[0;32m/usr/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
        "File \u001b[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-2a53b0fd-3a1d-4607-a075-bea4a60bfc49/lib/python3.11/site-packages/mlflow/store/_unity_catalog/registry/rest_store.py:715\u001b[0m, in \u001b[0;36mUcModelRegistryStore._local_model_dir\u001b[0;34m(self, source, local_model_path)\u001b[0m\n\u001b[1;32m    711\u001b[0m     local_model_dir \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39martifacts\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n\u001b[1;32m    712\u001b[0m         artifact_uri\u001b[38;5;241m=\u001b[39msource, tracking_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracking_uri\n\u001b[1;32m    713\u001b[0m     )\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 715\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to download model artifacts from source artifact location \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    717\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in order to upload them to Unity Catalog. Please ensure \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe source artifact location exists and that you can download from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit via mlflow.artifacts.download_artifacts()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    720\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m local_model_dir\n",
        "\u001b[0;31mMlflowException\u001b[0m: Unable to download model artifacts from source artifact location 'workspace.models.first-try-model' in order to upload them to Unity Catalog. Please ensure the source artifact location exists and that you can download from it via mlflow.artifacts.download_artifacts()"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"workspace\"\n",
    "schema = \"models\"\n",
    "model_name = \"first-try-model\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e71d8504-b543-4198-908a-2a9ca447beaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7905c9cc71499b996379bcc3d2179e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16409ee2098549af8a05cb1bfc070d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Deployment of workspace.models.first-try-model version 2 initiated.  This can take up to 15 minutes and the Review App & Query Endpoint will not work until this deployment finishes.\n",
      "\n",
      "    View status: https://dbc-05bab63c-84b8.cloud.databricks.com/ml/endpoints/agents_workspace-models-first-try-model\n",
      "    Review App: https://dbc-05bab63c-84b8.cloud.databricks.com/ml/review-v2/11a64ab1ac874e1f8d276ce4794a75ec/chat\n",
      "    Monitor: https://dbc-05bab63c-84b8.cloud.databricks.com/ml/experiments/2104128721751618/evaluation-monitoring\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Deployment(model_name='workspace.models.first-try-model', model_version='2', endpoint_name='agents_workspace-models-first-try-model', served_entity_name='workspace-models-first-try-model_2', query_endpoint='https://dbc-05bab63c-84b8.cloud.databricks.com/serving-endpoints/agents_workspace-models-first-try-model/served-models/workspace-models-first-try-model_2/invocations', endpoint_url='https://dbc-05bab63c-84b8.cloud.databricks.com/ml/endpoints/agents_workspace-models-first-try-model', review_app_url='https://dbc-05bab63c-84b8.cloud.databricks.com/ml/review-v2/11a64ab1ac874e1f8d276ce4794a75ec/chat')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from databricks import agents\n",
    "\n",
    "agents.deploy(\n",
    "    UC_MODEL_NAME,\n",
    "    uc_registered_model_info.version,\n",
    "    tags={\"endpointSource\": \"docs\"},\n",
    "    environment_vars={\n",
    "        \"DATABRICKS_GENIE_PAT\": f\"{{{{secrets/{secret_scope_name}/{secret_key_name}}}}}\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1aed4fff-48db-4dce-86d4-abc0317eae17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "w.secrets.put_secret(\"hackathon\",\"pat\",string_value =\"eyJraWQiOiJkZmJjOWVmMThjZTQ2ZTlhMDg2NWZmYzlkODkxYzJmMjg2NmFjMDM3MWZiNDlmOTdhMDg1MzBjNWYyODU3ZTg4IiwidHlwIjoiYXQrand0IiwiYWxnIjoiUlMyNTYifQ.eyJjbGllbnRfaWQiOiJjMjlhMDUzOS1jMjY1LTQyODQtODI5OC0yMGRkNDFjYTEyNGMiLCJzY29wZSI6ImFsbC1hcGlzIiwiaXNzIjoiaHR0cHM6Ly9hY2NvdW50cy5jbG91ZC5kYXRhYnJpY2tzLmNvbS9vaWRjL2FjY291bnRzL2I0YjNhN2I2LWFkNDQtNGY1NS05ZjJiLTVjYzE4ODgxZWUzOCIsImF1ZCI6ImI0YjNhN2I2LWFkNDQtNGY1NS05ZjJiLTVjYzE4ODgxZWUzOCIsInN1YiI6ImMyOWEwNTM5LWMyNjUtNDI4NC04Mjk4LTIwZGQ0MWNhMTI0YyIsImlhdCI6MTc0OTQ4OTk0MywiZXhwIjoxNzQ5NDkzNTQzLCJqdGkiOiIwMzZiOTliMS0yMzFjLTRhOGMtYmNhZC1iYmY5M2IwOTM1MjkifQ.OOFt0zEgRG-6POaVj1Br5PKZ49di8dDIC2uoyFytT48ZLBiukHS3jug_EKP7MJtsyX2dXBKYi0vghX35a3UFqxzROEQ7WYbqCEhI-dgnllwY5Bs6EOcQyuBMh9bRXAc3Uhm2lV4BvpkUxmULbVWBeWyBaw8Kbh4pfmBYpzkJ2QUdYdvqXzQKXPQmcfjczBDe1GOV47zJgreNvIN_xHy3KyOm2ERQZP58Xblv6tw2mzEtqve0M58dhdO4-G3Uip5ZGlHjUAtiEjymzeXeklYQ3zqkWSTbDyPozvqBg7-C0ujLOfNaIkEtT_wsWADHxLbc3SPwkSZfIPfOx8qI6-NeIQ\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6472415868083975,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Hackathon!!!",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
