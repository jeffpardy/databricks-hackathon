{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be141a7a-4242-45bf-be71-b1a6e6067c83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Enables autoreload; learn more at https://docs.databricks.com/en/files/workspace-modules.html#autoreload-for-python-modules\n",
    "# To disable autoreload; run %autoreload 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13e6f109-5913-4060-9466-e3ae494b9803",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Generate the access token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61518baa-6b7f-4e07-a04c-dd95e27663c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%sh\n",
    "\n",
    "export CLIENT_ID=c29a0539-c265-4284-8298-20dd41ca124c\n",
    "\n",
    "\n",
    "  curl --request POST \\\n",
    "  --url \"https://accounts.cloud.databricks.com/oidc/accounts/b4b3a7b6-ad44-4f55-9f2b-5cc18881ee38/v1/token\" \\\n",
    "  --user \"$CLIENT_ID:$CLIENT_SECRET\" \\\n",
    "  --data 'grant_type=client_credentials&scope=all-apis'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28646f8b-0a96-4117-aafb-62a24ad5d8fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Install all the Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8e91e9e-82ab-4742-b367-c2f5b80a1675",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -U -qqq mlflow langgraph==0.3.4 databricks-langchain databricks-agents uv databricks-vectorsearch\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8e009cc-250a-4734-9979-815b894de0a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Configure the Langgraph agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9908071-33bc-4557-a758-61008ffa2728",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile agent.py\n",
    "import functools\n",
    "import os\n",
    "from typing import Any, Generator, Literal, Optional\n",
    "\n",
    "import mlflow\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    UCFunctionToolkit,\n",
    ")\n",
    "from databricks_langchain.genie import GenieAgent\n",
    "from databricks_langchain import DatabricksVectorSearch\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentChunk,\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "from pydantic import BaseModel\n",
    "\n",
    "###################################################\n",
    "## Create a GenieAgent with access to a Genie Space\n",
    "###################################################\n",
    "\n",
    "# TODO add GENIE_SPACE_ID and a description for this space\n",
    "# You can find the ID in the URL of the genie room /genie/rooms/<GENIE_SPACE_ID>\n",
    "GENIE_SPACE_ID = \"01f0454b13a0192c9419325353b3aa99\"\n",
    "genie_agent_description = \"This agent can help find the right Medicare plan for a person based on a given set of filtered Medicare plans that are available in the state\"\n",
    "\n",
    "genie_agent = GenieAgent(\n",
    "    genie_space_id=GENIE_SPACE_ID,\n",
    "    genie_agent_name=\"Genie\",\n",
    "    description=genie_agent_description,\n",
    "    client=WorkspaceClient(\n",
    "        host=os.getenv(\"DB_MODEL_SERVING_HOST_URL\"),\n",
    "        token=os.getenv(\"DATABRICKS_GENIE_PAT\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "#######################################\n",
    "# Initialize the vector search engine\n",
    "#######################################\n",
    "\n",
    "# TODO: Configure your vector store parameters\n",
    "VECTOR_SEARCH_ENDPOINT = \"hackathon_search\"  # Replace with your endpoint\n",
    "VECTOR_INDEX_NAME = \"workspace.default.benefit_search\"  # Replace with your index\n",
    "\n",
    "vector_store = DatabricksVectorSearch(\n",
    "    endpoint=VECTOR_SEARCH_ENDPOINT,\n",
    "    index_name=VECTOR_INDEX_NAME,\n",
    "    columns=[\"plan_id\", \"contract_id\"]  # Columns to retrieve\n",
    ")\n",
    "\n",
    "#######################################\n",
    "# Define the clarification agent\n",
    "#######################################\n",
    "\n",
    "def clarification_agent(state):\n",
    "    prompt = \"Based on the conversation history, ask the user for the necessary information to find a suitable Medicare plan. Be specific about what you need (e.g., age, zip code, health conditions, current prescriptions). Be conversational and helpful.\"\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: state[\"messages\"] + [{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    clarification_chain = preprocessor | llm\n",
    "    response = clarification_chain.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": response.content,\n",
    "                \"name\": \"Clarification\",\n",
    "            }\n",
    "        ],\n",
    "        \"needs_user_input\": True  # Flag to indicate we need user response\n",
    "    }\n",
    "\n",
    "#######################################\n",
    "# Define the RAG agent for plan retrieval\n",
    "#######################################\n",
    "\n",
    "def rag_agent(state):\n",
    "    # Extract user requirements from conversation\n",
    "    messages = state.get(\"messages\", [])\n",
    "    \n",
    "    # Build search query from user information\n",
    "    user_info = []\n",
    "    search_query = \"\"\n",
    "    \n",
    "    # Parse messages to extract user requirements\n",
    "    for msg in messages:\n",
    "        if msg.get(\"role\") == \"user\":\n",
    "            user_info.append(msg.get(\"content\", \"\"))\n",
    "    \n",
    "    # Combine user information to create search query\n",
    "    search_query = \" \".join(user_info)\n",
    "    \n",
    "    try:\n",
    "        # Retrieve relevant plans from vector store\n",
    "        retriever = vector_store.as_retriever(\n",
    "            search_kwargs={\n",
    "                \"k\": 10,  # Number of plans to retrieve\n",
    "                \"filters\": {}  # Add filters if needed based on user requirements\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        relevant_plans = retriever.get_relevant_documents(search_query)\n",
    "        \n",
    "        # Format retrieved plans\n",
    "        if relevant_plans:\n",
    "            plans_info = []\n",
    "            plan_ids = []\n",
    "\n",
    "            for doc in relevant_plans:\n",
    "                plan_data = doc.metadata\n",
    "                plan_id = plan_data.get(\"plan_id\", \"N/A\")\n",
    "                contract_id = plan_data.get(\"contract_id\", \"N/A\")\n",
    "                \n",
    "                plans_info.append(f\"Plan ID: {plan_id}, Name: {contract_id}\")\n",
    "                if plan_id != \"N/A\":\n",
    "                    plan_ids.append(plan_id)\n",
    "            \n",
    "            retrieved_context = f\"Found {len(plan_ids)} Medicare plans matching your requirements:\\n\\n\" + \"\\n\".join(plans_info)\n",
    "\n",
    "            return {\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"assistant\", \n",
    "                        \"content\": f\"{retrieved_context}\\n\\nI'll now get detailed benefit information for these plans to help you choose the best one.\",\n",
    "                        \"name\": \"RAG\",\n",
    "                    }\n",
    "                ],\n",
    "                \"retrieved_plans\": [doc.metadata for doc in relevant_plans],\n",
    "                \"plan_ids\": plan_ids,  # Store just the plan IDs for Genie\n",
    "                \"needs_user_input\": False\n",
    "            }\n",
    "        else:\n",
    "            retrieved_context = \"I couldn't find any Medicare plans matching your specific requirements in our database.\"\n",
    "        \n",
    "        # Create response with retrieved plan information\n",
    "        prompt = f\"\"\"Based on the user's requirements and the following retrieved Medicare plan information, provide a helpful response about suitable Medicare plans:\n",
    "\n",
    "Retrieved Plans:\n",
    "{retrieved_context}\n",
    "\n",
    "Provide specific plan recommendations with plan IDs and explain why these plans might be suitable based on the user's stated needs.\"\"\"\n",
    "\n",
    "        preprocessor = RunnableLambda(\n",
    "            lambda state: state[\"messages\"] + [{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        rag_chain = preprocessor | llm\n",
    "        response = rag_chain.invoke(state)\n",
    "        \n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"assistant\", \n",
    "                    \"content\": response.content,\n",
    "                    \"name\": \"RAG\",\n",
    "                }\n",
    "            ],\n",
    "            \"retrieved_plans\": [doc.metadata for doc in relevant_plans],  # Store plan metadata\n",
    "            \"needs_user_input\": False\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Fallback if RAG fails\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": f\"I encountered an issue retrieving Medicare plans from our database. Let me route you to our Genie agent for assistance. Error: {str(e)}\",\n",
    "                    \"name\": \"RAG\",\n",
    "                }\n",
    "            ],\n",
    "            \"needs_user_input\": False\n",
    "        }\n",
    "\n",
    "\n",
    "############################################\n",
    "# Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "\n",
    "# TODO: Replace with your model serving endpoint\n",
    "# multi-agent Genie works best with claude 3.7 or gpt 4o models.\n",
    "LLM_ENDPOINT_NAME = \"databricks-llama-4-maverick\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "#############################\n",
    "# Define the supervisor agent\n",
    "#############################\n",
    "\n",
    "# TODO update the max number of iterations between supervisor and worker nodes\n",
    "# before returning to the user\n",
    "MAX_ITERATIONS = 5\n",
    "\n",
    "worker_descriptions = {\n",
    "    \"Genie\": genie_agent_description,\n",
    "    \"Clarification\": \"This agent help clarify the request of the user so that all needed information are provided.\",\n",
    "    \"RAG\": \"This agent retrieves specific Medicare plan IDs and details from the vector database based on user requirements.\",\n",
    "\n",
    "}\n",
    "\n",
    "formatted_descriptions = \"\\n\".join(\n",
    "    f\"- {name}: {desc}\" for name, desc in worker_descriptions.items()\n",
    ")\n",
    "\n",
    "system_prompt = f\"\"\"You are a supervisor agent. Your job is to route user requests to the appropriate worker agent or to a clarification agent if more information is needed.\n",
    "\n",
    "The available workers are:\n",
    "{formatted_descriptions}\n",
    "\n",
    "Analyze the conversation history to determine if the user has provided enough information to find a Medicare plan. You need details like:\n",
    "- Age or eligibility for Medicare\n",
    "- Location (zip code or state)\n",
    "- Current health status or conditions\n",
    "- Prescription drug needs\n",
    "- Budget considerations\n",
    "\n",
    "Analyze the conversation history to determine the next best action:\n",
    "\n",
    "1. If the user hasn't provided enough information for Medicare plan search (missing age, location, health conditions, prescriptions), route to 'Clarification'\n",
    "\n",
    "2. If the user has provided sufficient information but no specific plans have been retrieved yet, route to 'RAG' to search for relevant Medicare plans\n",
    "\n",
    "3. If specific plans have been retrieved then route to 'Genie' to retrieve benefits information about those plans and tell which plan would fit this person\n",
    "\n",
    "4. If the user's question has been fully answered, respond with 'FINISH'\n",
    "\n",
    "Current conversation context: Look at the messages to see what stage we're at in helping the user find a Medicare plan.\n",
    "\n",
    "Choose the next step carefully.\n",
    "\"\"\"\n",
    "\n",
    "options = [\"FINISH\", \"Clarification\"] + list(worker_descriptions.keys())\n",
    "FINISH = {\"next_node\": \"FINISH\"}\n",
    "\n",
    "def supervisor_agent(state):\n",
    "    count = state.get(\"iteration_count\", 0) + 1\n",
    "    if count > MAX_ITERATIONS:\n",
    "        return FINISH\n",
    "    \n",
    "    class nextNode(BaseModel):\n",
    "        next_node: Literal[tuple(options)]\n",
    "\n",
    "    preprocessor = RunnableLambda(\n",
    "        lambda state: [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    )\n",
    "    supervisor_chain = preprocessor | llm.with_structured_output(nextNode)\n",
    "    next_node = supervisor_chain.invoke(state).next_node\n",
    "    \n",
    "    # if routed back to the same node, exit the loop\n",
    "    if state.get(\"next_node\") == next_node:\n",
    "        return FINISH\n",
    "    return {\n",
    "        \"iteration_count\": count,\n",
    "        \"next_node\": next_node,\n",
    "        \"needs_user_input\": False\n",
    "    }\n",
    "\n",
    "#######################################\n",
    "# Define our multiagent graph structure\n",
    "#######################################\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": result[\"messages\"][-1].content,\n",
    "                \"name\": name,\n",
    "            }\n",
    "        ],\n",
    "        \"needs_user_input\": False\n",
    "    }\n",
    "\n",
    "def should_continue_or_end(state):\n",
    "    \"\"\"Decide whether to continue routing or end based on state\"\"\"\n",
    "    if state.get(\"needs_user_input\", False):\n",
    "        return \"END\"  # Stop here so user can respond to clarification\n",
    "    return \"supervisor\"  # Continue routing\n",
    "\n",
    "class AgentState(ChatAgentState):\n",
    "    next_node: str\n",
    "    iteration_count: int\n",
    "    needs_user_input: bool = False\n",
    "    retrieved_plans: list = []  # Store retrieved plan ids\n",
    "\n",
    "\n",
    "# clarification_node = functools.partial(agent_node, agent=clarification_agent, name=\"Clarification\")\n",
    "genie_node = functools.partial(agent_node, agent=genie_agent, name=\"Genie\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Genie\", genie_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_agent)\n",
    "workflow.add_node(\"Clarification\", clarification_agent)\n",
    "workflow.add_node(\"RAG\", rag_agent)\n",
    "\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "\n",
    "# - Genie and RAG always goes back to supervisor to check if more is needed\n",
    "# - Clarification can either go to END (for user input) or back to supervisor\n",
    "workflow.add_edge(\"Genie\", \"supervisor\")\n",
    "workflow.add_edge(\"RAG\", \"supervisor\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"Clarification\",\n",
    "    should_continue_or_end,\n",
    "    {\n",
    "        \"END\": END,\n",
    "        \"supervisor\": \"supervisor\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Let the supervisor decide which next node to go to\n",
    "conditional_edges = {k: k for k in worker_descriptions.keys()}\n",
    "conditional_edges[\"Clarification\"] = \"Clarification\"\n",
    "conditional_edges[\"FINISH\"] = END\n",
    "\n",
    "# Let the supervisor decide which next node to go\n",
    "workflow.add_conditional_edges(\n",
    "    \"supervisor\",\n",
    "    lambda x: x[\"next_node\"],\n",
    "    conditional_edges\n",
    ")\n",
    "multi_agent = workflow.compile()\n",
    "\n",
    "###################################\n",
    "# Wrap our multi-agent in ChatAgent\n",
    "###################################\n",
    "\n",
    "\n",
    "class LangGraphChatAgent(ChatAgent):\n",
    "    def __init__(self, agent: CompiledStateGraph):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        request = {\n",
    "            \"messages\": [m.model_dump_compat(exclude_none=True) for m in messages]\n",
    "        }\n",
    "\n",
    "        messages = []\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                new_messages = node_data.get(\"messages\", [])\n",
    "                if new_messages:\n",
    "                    messages.extend(\n",
    "                        ChatAgentMessage(**msg) for msg in node_data.get(\"messages\", [])\n",
    "                    )\n",
    "                    # If this is a clarification request, return immediately to allow user response\n",
    "                    if node_data.get(\"needs_user_input\", False):\n",
    "                        break\n",
    "        return ChatAgentResponse(messages=messages)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        messages: list[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[dict[str, Any]] = None,\n",
    "    ) -> Generator[ChatAgentChunk, None, None]:\n",
    "        request = {\n",
    "            \"messages\": [m.model_dump_compat(exclude_none=True) for m in messages]\n",
    "        }\n",
    "        for event in self.agent.stream(request, stream_mode=\"updates\"):\n",
    "            for node_data in event.values():\n",
    "                new_messages = node_data.get(\"messages\", [])\n",
    "                if new_messages:\n",
    "                    yield from (\n",
    "                        ChatAgentChunk(**{\"delta\": msg})\n",
    "                        for msg in node_data.get(\"messages\", [])\n",
    "                    )\n",
    "                    # If this is a clarification request, stop streaming to allow user response\n",
    "                    if node_data.get(\"needs_user_input\", False):\n",
    "                        break\n",
    "\n",
    "\n",
    "# Create the agent object, and specify it as the agent object to use when\n",
    "# loading the agent back for inference via mlflow.models.set_model()\n",
    "mlflow.langchain.autolog()\n",
    "AGENT = LangGraphChatAgent(multi_agent)\n",
    "mlflow.models.set_model(AGENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be561876-d3f3-465c-905c-5dd9f2db920f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Test the agent with a simple user message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a275b98-eb2e-4028-9603-018ec5825ca4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Workspace/Users/grangeranthony@gmail.com/agent.py:111: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  relevant_plans = retriever.get_relevant_documents(search_query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTICE] Using a notebook authentication token. Recommended for development only. For improved performance, please use Service Principal based authentication. To disable this message, pass disable_notice=True.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatAgentResponse(messages=[ChatAgentMessage(role='assistant', content=\"## Step 1: Understand the User's Requirements\\nThe user is a 70-year-old living in Dutchess County, seeking a teeth routine cleaning without dental insurance, and is looking for suitable Medicare plans.\\n\\n## Step 2: Identify Relevant Medicare Plan Information\\nThe retrieved Medicare plans are: H2624 (Plan IDs: 802, 803), H9808 (Plan IDs: 807, 808), H5521 (Plan IDs: 323, 459), H2775 (Plan IDs: 105, 112), H5216 (Plan ID: 382), and H2406 (Plan ID: 119).\\n\\n## Step 3: Analyze the Coverage for Dental Services\\nOriginal Medicare (Part A and Part B) does not typically cover routine dental care, including teeth cleanings. However, some Medicare Advantage plans may offer additional benefits, such as dental coverage.\\n\\n## Step 4: Determine Suitable Plans Based on the User's Needs\\nTo be suitable, a plan should be a Medicare Advantage plan that offers dental coverage, as the user is looking for coverage for a routine teeth cleaning.\\n\\n## Step 5: Examine the Retrieved Plans for Dental Coverage\\nWhile the specific details of the dental coverage for each plan are not provided, Medicare Advantage plans (like those listed with different plan IDs and names) often include additional benefits such as dental, vision, and hearing coverage. Plans with the same name (e.g., H2624, H9808, H5521, H2775) are likely from the same insurer but may have different details or service areas.\\n\\n## Step 6: Provide Recommendations\\nSince the user is looking for a routine teeth cleaning, we need to look for Medicare Advantage plans that include dental benefits. Without specific details on the dental coverage of each plan, we can still recommend exploring the plans listed for their dental benefits.\\n\\n## Step 7: Suggest Plans to Explore Further\\nThe user should explore the details of plans like H2624 (802, 803), H9808 (807, 808), H5521 (323, 459), H2775 (105, 112), H5216 (382), and H2406 (119) to see which ones offer dental coverage that includes routine cleanings.\\n\\n## Step 8: Consideration of Plan Details\\nThe user should compare the dental benefits, premiums, deductibles, and any out-of-pocket costs associated with each plan. It's also crucial to verify that the plans are available in Dutchess County.\\n\\n## Step 9: Finalizing the Recommendation\\nGiven the information, suitable plans would be those that are Medicare Advantage plans offering dental coverage. The user should check the specifics of plans like H2624, H9808, H5521, H2775, H5216, and H2406 for dental benefits.\\n\\nThe final answer is: $\\\\boxed{807}$\", name='RAG', id='1d148708-622b-4d08-a9e6-528548a3b9d5', tool_calls=None, tool_call_id=None, attachments=None), ChatAgentMessage(role='assistant', content='The provided chat history is unrelated to the database schema and tables available. I can only assist with queries related to the provided database schema and tables. Please provide a relevant question or request related to the available data.', name='Genie', id='ca04b032-10ea-464b-ac8e-c3395282db7e', tool_calls=None, tool_call_id=None, attachments=None)], finish_reason=None, custom_outputs=None, usage=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/databricks.mlflow.trace": "\"tr-86e9ab391f1646dba8f5697d133e2db8\"",
      "text/plain": [
       "Trace(request_id=tr-86e9ab391f1646dba8f5697d133e2db8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agent import AGENT\n",
    "\n",
    "input_example = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I am 70 years old and live in dutchess county. I am looking for a teeth routine cleaning. I do not have any other health conditions. I do not have dental insurance.\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "AGENT.predict(input_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efb13c1e-5a83-4aa7-8e6a-cc6c4fdfa828",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Set the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75432653-c82e-4c14-bff3-c1f4ee2ca90f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dbruntime.databricks_repl_context import get_context\n",
    "\n",
    "# TODO: set secret_scope_name and secret_key_name to access your PAT\n",
    "secret_scope_name = \"hackathon\"\n",
    "secret_key_name = \"pat\"\n",
    "\n",
    "os.environ[\"DB_MODEL_SERVING_HOST_URL\"] = \"https://dbc-05bab63c-84b8.cloud.databricks.com/browse/folders/workspace?o=806146813099306\"\n",
    "assert os.environ[\"DB_MODEL_SERVING_HOST_URL\"] is not None\n",
    "os.environ[\"DATABRICKS_GENIE_PAT\"] = dbutils.secrets.get(\n",
    "    scope=secret_scope_name, key=secret_key_name\n",
    ")\n",
    "assert os.environ[\"DATABRICKS_GENIE_PAT\"] is not None, (\n",
    "    \"The DATABRICKS_GENIE_PAT was not properly set to the PAT secret\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6c37bd3-a098-49d8-90c3-ee2cbbdedcca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Register the model with mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f56a3cd7-8df3-4cfd-bbcc-b042ab4c4f02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 18:49:09 INFO mlflow.pyfunc: Predicting on input example to validate output\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7b98d7a877451dae34c8a82a2824dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine Databricks resources to specify for automatic auth passthrough at deployment time\n",
    "import mlflow\n",
    "from agent import GENIE_SPACE_ID, LLM_ENDPOINT_NAME\n",
    "from databricks_langchain import UnityCatalogTool, VectorSearchRetrieverTool\n",
    "from mlflow.models.resources import (\n",
    "    DatabricksFunction,\n",
    "    DatabricksGenieSpace,\n",
    "    DatabricksServingEndpoint,\n",
    ")\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "# TODO: Manually include underlying resources if needed. See the TODO in the markdown above for more information.\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME),\n",
    "    DatabricksGenieSpace(genie_space_id=GENIE_SPACE_ID),\n",
    "#   DatabricksSQLWarehouse(warehouse_id=\"your_warehouse_id\"),\n",
    "#   DatabricksTable(table_name=\"your_table_name\"),\n",
    "]\n",
    "\n",
    "# for tool in tools:\n",
    "#     if isinstance(tool, VectorSearchRetrieverTool):\n",
    "#         resources.extend(tool.resources)\n",
    "#     elif isinstance(tool, UnityCatalogTool):\n",
    "#         resources.append(DatabricksFunction(function_name=tool.uc_function_name))\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        input_example=input_example,\n",
    "        extra_pip_requirements=[f\"databricks-connect=={get_distribution('databricks-connect').version}\"],\n",
    "        resources=resources,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eeab4c70-d54a-4cdb-bde3-5f9d8c808d97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Test the deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "314d87ce-fac5-4622-9825-5d2b8b80c2cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ef26d6ddfb4c4c91f2a851e5792c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 18:50:41 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b563fa05a4043a28790ca5706d8c03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 18:50:43 INFO mlflow.utils.virtualenv: Creating a new environment in /tmp/virtualenv_envs/mlflow-3e34192403d42e40bc5d898d008b8ab35e3e7faf with python version 3.11.10 using uv\n",
      "Using CPython 3.11.10 interpreter at: \u001b[36m/usr/bin/python3.11\u001b[39m\n",
      "Creating virtual environment at: \u001b[36m/tmp/virtualenv_envs/mlflow-3e34192403d42e40bc5d898d008b8ab35e3e7faf\u001b[39m\n",
      "Activate with: \u001b[32msource /tmp/virtualenv_envs/mlflow-3e34192403d42e40bc5d898d008b8ab35e3e7faf/bin/activate\u001b[39m\n",
      "2025/06/09 18:50:44 INFO mlflow.utils.virtualenv: Installing dependencies\n",
      "\u001b[2mUsing Python 3.11.10 environment at: /tmp/virtualenv_envs/mlflow-3e34192403d42e40bc5d898d008b8ab35e3e7faf\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m3 packages\u001b[0m \u001b[2min 95ms\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m setuptools \u001b[2m(1.2MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pip \u001b[2m(1.7MiB)\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pip\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m setuptools\n",
      "\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 132ms\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 23ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpip\u001b[0m\u001b[2m==24.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msetuptools\u001b[0m\u001b[2m==75.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwheel\u001b[0m\u001b[2m==0.38.4\u001b[0m\n",
      "\u001b[2mUsing Python 3.11.10 environment at: /tmp/virtualenv_envs/mlflow-3e34192403d42e40bc5d898d008b8ab35e3e7faf\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m159 packages\u001b[0m \u001b[2min 1.87s\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m scikit-learn \u001b[2m(12.3MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pygments \u001b[2m(1.2MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m mlflow-skinny \u001b[2m(6.0MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m botocore \u001b[2m(13.0MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m jedi \u001b[2m(1.5MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m aiohttp \u001b[2m(1.6MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m matplotlib \u001b[2m(8.2MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m sqlalchemy \u001b[2m(3.1MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m kiwisolver \u001b[2m(1.4MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m mlflow \u001b[2m(27.7MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pydantic-core \u001b[2m(1.9MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pandas \u001b[2m(11.5MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m grpcio \u001b[2m(5.8MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m tiktoken \u001b[2m(1.1MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pillow \u001b[2m(4.4MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m cryptography \u001b[2m(4.3MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m zstandard \u001b[2m(5.2MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m langchain-community \u001b[2m(2.4MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m numpy \u001b[2m(17.4MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pyarrow \u001b[2m(36.2MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m fonttools \u001b[2m(4.7MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m cython \u001b[2m(1.8MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m scipy \u001b[2m(33.6MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m databricks-connect \u001b[2m(2.3MiB)\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m tiktoken\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m kiwisolver\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pygments\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m aiohttp\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m cython\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pydantic-core\n",
      "   \u001b[36m\u001b[1mBuilding\u001b[0m\u001b[39m psutil\u001b[2m==5.9.0\u001b[0m\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m databricks-connect\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m sqlalchemy\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pillow\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m cryptography\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m fonttools\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m zstandard\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m langchain-community\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m grpcio\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m matplotlib\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m mlflow-skinny\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pandas\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m jedi\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m scikit-learn\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m numpy\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m mlflow\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m scipy\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m botocore\n",
      " \u001b[32m\u001b[1mDownloading\u001b[0m\u001b[39m pyarrow\n",
      "      \u001b[32m\u001b[1mBuilt\u001b[0m\u001b[39m psutil\u001b[2m==5.9.0\u001b[0m\n",
      "\u001b[2mPrepared \u001b[1m158 packages\u001b[0m \u001b[2min 9.83s\u001b[0m\u001b[0m\n",
      "\u001b[2mInstalled \u001b[1m158 packages\u001b[0m \u001b[2min 572ms\u001b[0m\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohappyeyeballs\u001b[0m\u001b[2m==2.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohttp\u001b[0m\u001b[2m==3.12.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohttp-retry\u001b[0m\u001b[2m==2.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiosignal\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1malembic\u001b[0m\u001b[2m==1.16.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mannotated-types\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1manyio\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mattrs\u001b[0m\u001b[2m==25.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mazure-core\u001b[0m\u001b[2m==1.34.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mazure-storage-blob\u001b[0m\u001b[2m==12.26.0b1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mazure-storage-file-datalake\u001b[0m\u001b[2m==12.21.0b1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mblinker\u001b[0m\u001b[2m==1.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mboto3\u001b[0m\u001b[2m==1.38.32\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mbotocore\u001b[0m\u001b[2m==1.38.32\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcachetools\u001b[0m\u001b[2m==5.5.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcertifi\u001b[0m\u001b[2m==2025.4.26\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcffi\u001b[0m\u001b[2m==1.17.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcharset-normalizer\u001b[0m\u001b[2m==3.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mclick\u001b[0m\u001b[2m==8.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcloudpickle\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcontourpy\u001b[0m\u001b[2m==1.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcryptography\u001b[0m\u001b[2m==45.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcycler\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcython\u001b[0m\u001b[2m==0.29.32\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatabricks-agents\u001b[0m\u001b[2m==0.22.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatabricks-ai-bridge\u001b[0m\u001b[2m==0.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatabricks-connect\u001b[0m\u001b[2m==16.1.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatabricks-langchain\u001b[0m\u001b[2m==0.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatabricks-sdk\u001b[0m\u001b[2m==0.56.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatabricks-vectorsearch\u001b[0m\u001b[2m==0.56\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdataclasses-json\u001b[0m\u001b[2m==0.6.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdeprecation\u001b[0m\u001b[2m==2.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdocker\u001b[0m\u001b[2m==7.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastapi\u001b[0m\u001b[2m==0.115.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mflask\u001b[0m\u001b[2m==3.1.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfonttools\u001b[0m\u001b[2m==4.58.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfrozenlist\u001b[0m\u001b[2m==1.6.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgitdb\u001b[0m\u001b[2m==4.0.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgitpython\u001b[0m\u001b[2m==3.1.44\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-api-core\u001b[0m\u001b[2m==2.25.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-auth\u001b[0m\u001b[2m==2.40.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-cloud-core\u001b[0m\u001b[2m==2.4.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-cloud-storage\u001b[0m\u001b[2m==2.18.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-crc32c\u001b[0m\u001b[2m==1.7.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-resumable-media\u001b[0m\u001b[2m==2.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogleapis-common-protos\u001b[0m\u001b[2m==1.70.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgraphene\u001b[0m\u001b[2m==3.4.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgraphql-core\u001b[0m\u001b[2m==3.2.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgraphql-relay\u001b[0m\u001b[2m==3.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgreenlet\u001b[0m\u001b[2m==3.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.73.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio-status\u001b[0m\u001b[2m==1.71.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgunicorn\u001b[0m\u001b[2m==23.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mh11\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpcore\u001b[0m\u001b[2m==1.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx\u001b[0m\u001b[2m==0.28.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhttpx-sse\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1midna\u001b[0m\u001b[2m==3.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mimportlib-metadata\u001b[0m\u001b[2m==8.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==8.25.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1misodate\u001b[0m\u001b[2m==0.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mitsdangerous\u001b[0m\u001b[2m==2.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjinja2\u001b[0m\u001b[2m==3.1.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjmespath\u001b[0m\u001b[2m==1.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjoblib\u001b[0m\u001b[2m==1.5.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonpatch\u001b[0m\u001b[2m==1.33\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonpointer\u001b[0m\u001b[2m==3.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mkiwisolver\u001b[0m\u001b[2m==1.4.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain\u001b[0m\u001b[2m==0.3.25\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-community\u001b[0m\u001b[2m==0.3.24\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-core\u001b[0m\u001b[2m==0.3.64\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangchain-text-splitters\u001b[0m\u001b[2m==0.3.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanggraph\u001b[0m\u001b[2m==0.3.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanggraph-checkpoint\u001b[0m\u001b[2m==2.0.26\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanggraph-prebuilt\u001b[0m\u001b[2m==0.1.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanggraph-sdk\u001b[0m\u001b[2m==0.1.70\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangsmith\u001b[0m\u001b[2m==0.3.45\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmako\u001b[0m\u001b[2m==1.3.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkdown\u001b[0m\u001b[2m==3.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarkupsafe\u001b[0m\u001b[2m==3.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarshmallow\u001b[0m\u001b[2m==3.26.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib\u001b[0m\u001b[2m==3.10.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.1.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmlflow\u001b[0m\u001b[2m==2.22.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmlflow-skinny\u001b[0m\u001b[2m==2.22.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmultidict\u001b[0m\u001b[2m==6.4.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmypy-extensions\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnumpy\u001b[0m\u001b[2m==1.26.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-api\u001b[0m\u001b[2m==1.34.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-sdk\u001b[0m\u001b[2m==1.34.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopentelemetry-semantic-conventions\u001b[0m\u001b[2m==0.55b0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1morjson\u001b[0m\u001b[2m==3.10.18\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mormsgpack\u001b[0m\u001b[2m==1.10.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpackaging\u001b[0m\u001b[2m==24.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==1.5.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.51\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpropcache\u001b[0m\u001b[2m==0.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mproto-plus\u001b[0m\u001b[2m==1.26.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mprotobuf\u001b[0m\u001b[2m==5.29.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==5.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpy4j\u001b[0m\u001b[2m==0.10.9.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyarrow\u001b[0m\u001b[2m==14.0.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1\u001b[0m\u001b[2m==0.6.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyasn1-modules\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpycparser\u001b[0m\u001b[2m==2.22\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic\u001b[0m\u001b[2m==2.11.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-core\u001b[0m\u001b[2m==2.33.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpydantic-settings\u001b[0m\u001b[2m==2.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyparsing\u001b[0m\u001b[2m==3.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dateutil\u001b[0m\u001b[2m==2.9.0.post0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpython-dotenv\u001b[0m\u001b[2m==1.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpytz\u001b[0m\u001b[2m==2025.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpyyaml\u001b[0m\u001b[2m==6.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mregex\u001b[0m\u001b[2m==2024.11.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests\u001b[0m\u001b[2m==2.32.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrequests-toolbelt\u001b[0m\u001b[2m==1.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mrsa\u001b[0m\u001b[2m==4.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1ms3transfer\u001b[0m\u001b[2m==0.13.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscikit-learn\u001b[0m\u001b[2m==1.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mscipy\u001b[0m\u001b[2m==1.16.0rc2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msix\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msmmap\u001b[0m\u001b[2m==5.0.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msniffio\u001b[0m\u001b[2m==1.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msqlalchemy\u001b[0m\u001b[2m==2.0.41\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msqlparse\u001b[0m\u001b[2m==0.5.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstarlette\u001b[0m\u001b[2m==0.46.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtabulate\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtenacity\u001b[0m\u001b[2m==9.1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthreadpoolctl\u001b[0m\u001b[2m==3.6.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtiktoken\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.3.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtqdm\u001b[0m\u001b[2m==4.67.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-extensions\u001b[0m\u001b[2m==4.14.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspect\u001b[0m\u001b[2m==0.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyping-inspection\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1munitycatalog-ai\u001b[0m\u001b[2m==0.3.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1munitycatalog-client\u001b[0m\u001b[2m==0.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1munitycatalog-langchain\u001b[0m\u001b[2m==0.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muvicorn\u001b[0m\u001b[2m==0.34.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.13\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwerkzeug\u001b[0m\u001b[2m==3.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1myarl\u001b[0m\u001b[2m==1.20.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mzipp\u001b[0m\u001b[2m==3.23.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mzstandard\u001b[0m\u001b[2m==0.23.0\u001b[0m\n",
      "2025/06/09 18:50:57 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /tmp/virtualenv_envs/mlflow-3e34192403d42e40bc5d898d008b8ab35e3e7faf/bin/activate && python -c \"\"']'\n",
      "2025/06/09 18:50:57 INFO mlflow.utils.environment: === Running command '['bash', '-c', 'source /tmp/virtualenv_envs/mlflow-3e34192403d42e40bc5d898d008b8ab35e3e7faf/bin/activate && python /local_disk0/.ephemeral_nfs/envs/pythonEnv-028b38a7-210b-4bee-b259-dd4eebaa8511/lib/python3.11/site-packages/mlflow/pyfunc/_mlflow_pyfunc_backend_predict.py --model-uri file:///local_disk0/user_tmp_data/spark-028b38a7-210b-4bee-b259-dd/tmpnxke_lp_/agent --content-type json --input-path /local_disk0/user_tmp_data/spark-028b38a7-210b-4bee-b259-dd/tmpt302eu0_/input.json']'\n",
      "Mon Jun  9 18:51:09 2025 Connection to spark from PID  15565\n",
      "Mon Jun  9 18:51:09 2025 Initialized gateway on port 39887\n",
      "Mon Jun  9 18:51:10 2025 Connected to spark.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"messages\": [{\"role\": \"assistant\", \"content\": \"You're looking for a Medicare plan that covers your dental needs. I'd be happy to help you figure out the best option.\\n\\nTo get started, can you please tell me a bit more about your situation? \\n\\nSpecifically, I need to know:\\n\\n1. **Your age**: Are you 65 or older, or are you under 65 with a disability?\\n2. **Your location**: What's your zip code? Medicare plans vary by location, so this will help me narrow down the options.\\n3. **Your dental needs**: Are you looking for routine care like cleanings and check-ups, or do you need more extensive coverage for procedures like crowns, dentures, or implants?\\n4. **Current Medicare coverage**: Are you already enrolled in Medicare Part A and/or Part B, or are you new to Medicare?\\n5. **Additional health needs**: Do you have any other health conditions or take prescription medications that you'd like to ensure are covered by your Medicare plan?\\n\\nOnce I have this information, I can help you explore Medicare plans that fit your needs, including Medicare Advantage plans that often include dental coverage. Let's get started!\", \"name\": \"Clarification\", \"id\": \"5bcb4c82-296a-4ff7-afed-23dc7ae62917\"}]}"
     ]
    }
   ],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data=input_example,\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7155b22-1cdd-4331-b294-26549faf4630",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'workspace.models.first-try-model' already exists. Creating a new version of this model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfe0da4d34e4010a5d33a09f2cb60da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3ff7d763f64c29be01894b85b855dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'workspace.models.first-try-model'.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"workspace\"\n",
    "schema = \"models\"\n",
    "model_name = \"first-try-model\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e71d8504-b543-4198-908a-2a9ca447beaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f7905c9cc71499b996379bcc3d2179e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16409ee2098549af8a05cb1bfc070d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Deployment of workspace.models.first-try-model version 2 initiated.  This can take up to 15 minutes and the Review App & Query Endpoint will not work until this deployment finishes.\n",
      "\n",
      "    View status: https://dbc-05bab63c-84b8.cloud.databricks.com/ml/endpoints/agents_workspace-models-first-try-model\n",
      "    Review App: https://dbc-05bab63c-84b8.cloud.databricks.com/ml/review-v2/11a64ab1ac874e1f8d276ce4794a75ec/chat\n",
      "    Monitor: https://dbc-05bab63c-84b8.cloud.databricks.com/ml/experiments/2104128721751618/evaluation-monitoring\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Deployment(model_name='workspace.models.first-try-model', model_version='2', endpoint_name='agents_workspace-models-first-try-model', served_entity_name='workspace-models-first-try-model_2', query_endpoint='https://dbc-05bab63c-84b8.cloud.databricks.com/serving-endpoints/agents_workspace-models-first-try-model/served-models/workspace-models-first-try-model_2/invocations', endpoint_url='https://dbc-05bab63c-84b8.cloud.databricks.com/ml/endpoints/agents_workspace-models-first-try-model', review_app_url='https://dbc-05bab63c-84b8.cloud.databricks.com/ml/review-v2/11a64ab1ac874e1f8d276ce4794a75ec/chat')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from databricks import agents\n",
    "\n",
    "agents.deploy(\n",
    "    UC_MODEL_NAME,\n",
    "    uc_registered_model_info.version,\n",
    "    tags={\"endpointSource\": \"docs\"},\n",
    "    environment_vars={\n",
    "        \"DATABRICKS_GENIE_PAT\": f\"{{{{secrets/{secret_scope_name}/{secret_key_name}}}}}\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1aed4fff-48db-4dce-86d4-abc0317eae17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "w.secrets.put_secret(\"hackathon\",\"pat\",string_value =\"eyJraWQiOiJkZmJjOWVmMThjZTQ2ZTlhMDg2NWZmYzlkODkxYzJmMjg2NmFjMDM3MWZiNDlmOTdhMDg1MzBjNWYyODU3ZTg4IiwidHlwIjoiYXQrand0IiwiYWxnIjoiUlMyNTYifQ.eyJjbGllbnRfaWQiOiJjMjlhMDUzOS1jMjY1LTQyODQtODI5OC0yMGRkNDFjYTEyNGMiLCJzY29wZSI6ImFsbC1hcGlzIiwiaXNzIjoiaHR0cHM6Ly9hY2NvdW50cy5jbG91ZC5kYXRhYnJpY2tzLmNvbS9vaWRjL2FjY291bnRzL2I0YjNhN2I2LWFkNDQtNGY1NS05ZjJiLTVjYzE4ODgxZWUzOCIsImF1ZCI6ImI0YjNhN2I2LWFkNDQtNGY1NS05ZjJiLTVjYzE4ODgxZWUzOCIsInN1YiI6ImMyOWEwNTM5LWMyNjUtNDI4NC04Mjk4LTIwZGQ0MWNhMTI0YyIsImlhdCI6MTc0OTQ4OTk0MywiZXhwIjoxNzQ5NDkzNTQzLCJqdGkiOiIwMzZiOTliMS0yMzFjLTRhOGMtYmNhZC1iYmY5M2IwOTM1MjkifQ.OOFt0zEgRG-6POaVj1Br5PKZ49di8dDIC2uoyFytT48ZLBiukHS3jug_EKP7MJtsyX2dXBKYi0vghX35a3UFqxzROEQ7WYbqCEhI-dgnllwY5Bs6EOcQyuBMh9bRXAc3Uhm2lV4BvpkUxmULbVWBeWyBaw8Kbh4pfmBYpzkJ2QUdYdvqXzQKXPQmcfjczBDe1GOV47zJgreNvIN_xHy3KyOm2ERQZP58Xblv6tw2mzEtqve0M58dhdO4-G3Uip5ZGlHjUAtiEjymzeXeklYQ3zqkWSTbDyPozvqBg7-C0ujLOfNaIkEtT_wsWADHxLbc3SPwkSZfIPfOx8qI6-NeIQ\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6472415868083975,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Hackathon!!!",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
